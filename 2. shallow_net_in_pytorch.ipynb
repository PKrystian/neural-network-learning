{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcrCNS6jc5-e"
   },
   "source": [
    "# Płytka sieć neuronowa w PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEygUgLVKJ7x"
   },
   "source": [
    "### Zaimportujmy zależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfFVh41odSXB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QCoX-S6dj54"
   },
   "source": [
    "### Załadujmy dane i od razu przeskalujmy (funkcja ToTensor konwertuje piksele z [0,255] na [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "UXk2_Pazef4W",
    "outputId": "1482c5ea-0451-453a-b762-43a658f50d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 25407420.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 94933929.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 6019414.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 20797520.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = MNIST('data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdźmy jak wyglądają dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EdMVpcOHetgf",
    "outputId": "488de8ea-f066-438b-dafc-2748a6f28b8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1002
    },
    "colab_type": "code",
    "id": "yZ8hKPF6exuw",
    "outputId": "210219ce-d5d8-4b06-9db4-bcbc1472f973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zobaczmy konkretne wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "vzITvYebe6NQ",
    "outputId": "6c3faad1-d5fd-4000-9337-2de757b1bef8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbd93b80450>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train.data[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "kf4i8Q09fCpw",
    "outputId": "55a78ab8-7a11-47a0-e9a9-a59e2a4c803b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
       "        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
       "        7, 8, 3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.targets[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e6d0sd_8fQPH",
    "outputId": "3ecf50a1-8220-4ea7-9f59-d5efdf235bf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0qST6tDffR9v",
    "outputId": "6f7fa323-d560-4e28-f753-1832658ed45b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WyPpoB3dfiwo",
    "outputId": "15ac5f38-8716-4189-edd3-b8e13f84d4bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYMXOGJvfkCo"
   },
   "source": [
    "### Popaczkujmy zbiór danych z wykorzystaniem klasy DataLoader i przejrzyjmy paczki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IySNK8Ef6Eq"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_batches = len(test_loader)\n",
    "n_test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLfWTrjshEsh"
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5fc-M4JCiRTW",
    "outputId": "746dc866-ee0a-422d-98b9-a8045558070a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2TCZnZR-iWvo",
    "outputId": "396a086b-2155-476b-8b18-6c903dda106f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "8uk1_iPDiXR7",
    "outputId": "a820ebe3-cc65-40db-9974-0d755eadb103"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 2, 5, 4, 7, 1, 0, 9, 8, 7, 8, 9, 0, 7, 7, 3, 0, 8, 4, 5, 6, 5, 7,\n",
       "        6, 6, 2, 5, 0, 9, 0, 7, 4, 2, 7, 5, 2, 0, 7, 3, 8, 5, 2, 2, 9, 0, 6, 0,\n",
       "        5, 5, 5, 8, 7, 7, 9, 7, 3, 5, 0, 1, 1, 9, 7, 6, 1, 5, 8, 0, 6, 0, 9, 8,\n",
       "        6, 3, 2, 8, 4, 1, 3, 5, 7, 3, 5, 0, 9, 1, 6, 0, 0, 5, 9, 6, 1, 0, 3, 2,\n",
       "        0, 6, 3, 6, 4, 6, 5, 9, 7, 9, 0, 5, 5, 6, 6, 1, 1, 1, 6, 3, 4, 0, 6, 4,\n",
       "        1, 7, 5, 2, 8, 4, 8, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1952
    },
    "colab_type": "code",
    "id": "Sf4z56RKi1ja",
    "outputId": "a6ea24fe-4730-4ab5-9abf-36e99d12b1d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.5412, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.5804, 0.2039, 0.0000,\n",
       "          0.0000, 0.0000, 0.6510, 0.8314, 0.0588, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9922, 0.7294, 0.0000,\n",
       "          0.0000, 0.0000, 0.5216, 0.9922, 0.2157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0235, 0.7922, 0.9922, 0.9922, 0.2314,\n",
       "          0.0000, 0.0000, 0.0235, 0.6627, 0.8118, 0.0471, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1412, 0.9922, 0.9922, 0.8980, 0.3412,\n",
       "          0.0000, 0.0000, 0.0000, 0.6510, 0.9922, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4275, 0.8824, 0.9922, 0.7373, 0.3686, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.3137, 0.9922, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1059, 0.8824, 0.9922, 0.9922, 0.2588, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2196, 0.9922, 0.0863, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2196, 0.9922, 0.9922, 0.9647, 0.2118, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2196, 0.9922, 0.1608, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.5373, 0.9922, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.2196, 0.9922, 0.5137, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6510, 0.9922, 0.9569, 0.0510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5961, 0.9922, 0.7059, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.9961, 0.9961, 0.8980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3373, 1.0000, 0.9961, 0.7059, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3922, 0.9922, 0.9922, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.6353, 0.9922, 0.9922, 0.2157, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5216, 0.9922, 0.8588, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1569, 0.9686, 0.9922, 0.6863, 0.0510, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.9373, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "          0.2039, 0.8941, 0.9922, 0.8784, 0.1020, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5765, 0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275,\n",
       "          0.9922, 0.9922, 0.9765, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.9922, 0.6471, 0.0000, 0.0000, 0.2588, 0.7255, 0.9059,\n",
       "          0.9922, 0.9922, 0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0471, 0.8275, 0.9647, 0.5137, 0.7412, 0.9725, 0.9922, 0.9961,\n",
       "          0.9922, 0.5961, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3490, 0.9569, 0.9922, 0.9922, 0.9922, 0.9922, 0.9765,\n",
       "          0.5176, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.6471, 0.9922, 0.9922, 0.9922, 0.5373, 0.2275,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0471, 0.3569, 0.7294, 0.2392, 0.0196, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spłaszczamy paczkę \n",
    "(niespodzianie służy do tego funkcja .view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlj29yCske1c"
   },
   "outputs": [],
   "source": [
    "X_flat_sample = X_sample.view(X_sample.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8VtnEEvLi4UD",
    "outputId": "bf534ee2-d23d-4c01-8060-09ec72222cb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1537
    },
    "colab_type": "code",
    "id": "Koet4ZSgkSHu",
    "outputId": "8334d8fb-0538-4e7e-d534-9d3829d995c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.2549, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471,\n",
       "        0.5804, 0.2039, 0.0000, 0.0000, 0.0000, 0.6510, 0.8314, 0.0588, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.1765, 0.9922, 0.7294, 0.0000, 0.0000, 0.0000, 0.5216, 0.9922, 0.2157,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0235, 0.7922, 0.9922, 0.9922, 0.2314, 0.0000, 0.0000, 0.0235, 0.6627,\n",
       "        0.8118, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1412, 0.9922, 0.9922, 0.8980, 0.3412, 0.0000, 0.0000, 0.0000,\n",
       "        0.6510, 0.9922, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.4275, 0.8824, 0.9922, 0.7373, 0.3686, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.3137, 0.9922, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1059, 0.8824, 0.9922, 0.9922, 0.2588, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.2196, 0.9922, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.2196, 0.9922, 0.9922, 0.9647, 0.2118, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.2196, 0.9922, 0.1608, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.5373, 0.9922, 0.9922, 0.5020, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.2196, 0.9922, 0.5137, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.6510, 0.9922, 0.9569, 0.0510, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.9922, 0.7059, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.9961, 0.9961, 0.8980, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373, 1.0000, 0.9961, 0.7059,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.9922, 0.9922, 0.4039,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6353, 0.9922, 0.9922,\n",
       "        0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9922, 0.8588,\n",
       "        0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.9686, 0.9922,\n",
       "        0.6863, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9373, 0.9922,\n",
       "        0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.2039, 0.8941, 0.9922,\n",
       "        0.8784, 0.1020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5765,\n",
       "        0.9922, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 0.9922, 0.9922,\n",
       "        0.9765, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0902, 0.9922, 0.6471, 0.0000, 0.0000, 0.2588, 0.7255, 0.9059, 0.9922,\n",
       "        0.9922, 0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0471, 0.8275, 0.9647, 0.5137, 0.7412, 0.9725, 0.9922, 0.9961,\n",
       "        0.9922, 0.5961, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.3490, 0.9569, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "        0.9765, 0.5176, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6471, 0.9922, 0.9922, 0.9922,\n",
       "        0.5373, 0.2275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.3569, 0.7294,\n",
       "        0.2392, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-lTFFhdkogC"
   },
   "source": [
    "### Czas na zaprojektowanie architektury sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch opiera się na modułach (obiektach klasy `torch.nn.Module`), które są łączone w graf obliczeń. Moduły mogą wykorzystywać parametry (obiekty klasy `torch.nn.Parameter`), dla których mogą być automatycznie liczone gradienty i które mogą podlegać optymalizacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1. Zadeklaruj odpowiedni rozmiar wejścia i wyjścia tak, by warstwa wejściowa przyjęła pojedynczo wszystkie piksele obrazka, a warstwa wyjściowa mogła reprezentować każdą z klas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkwmSP10k8Y7"
   },
   "outputs": [],
   "source": [
    "n_input = 28*28\n",
    "n_dense = 64\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy model, składający się z sekwencji warstw: wejściowej warstwy liniowej czyli warstwy implementującej operację $\\hat{y} = Wx + b$, (zwróćmy uwagę na jej liczbę wejść i wyjść), ukrytej warstwy gęstej o 64 neuronach z sigmoidalną funkcją aktywacji oraz wyjściowej warstwy liniowej (tu również zwróćmy uwagę na liczbę wejść)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLAYTQcrk208"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(n_input, n_dense),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(n_dense, n_out)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "ELhOOEzcmMjN",
    "outputId": "0bedac30-6b93-493f-c1a7-50f6c528a772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]          50,240\n",
      "           Sigmoid-2                [-1, 1, 64]               0\n",
      "            Linear-3                [-1, 1, 10]             650\n",
      "================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, n_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ad12qUaumQNF"
   },
   "source": [
    "### Skonfigurujmy hiperparametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2. Zajrzyj do dokumentacji biblioteki torch i zadeklaruj entropię skrośną (CrossEntropy) jako funkcję straty oraz SGD jako algorytm optymalizacji - z parametrami modelu jako parametrami do optymalizacji, oraz ze stałą uczenia równą 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MApHSXQGmfdE"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2568787117.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cost_fxn =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cost_fxn = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0c1Iqnpm32m"
   },
   "outputs": [],
   "source": [
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3836ImZnQ6_"
   },
   "source": [
    "### Zdefinujmy metrykę trafności prognozy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3. Zdefiniuj metrykę trafności prognozy, ustawiając następujące linijki w odpowiedniej kolejności w miejscach ...**\n",
    "    \n",
    "    1. correct = (prediction == true_y).sum().item()\n",
    "    2. (correct / true_y.shape[0]) * 100.0\n",
    "    3. _, prediction = torch.max(pred_y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9iTkEv6nVHB"
   },
   "outputs": [],
   "source": [
    "def accuracy_pct(pred_y, true_y):\n",
    "    ...\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wreszcie nauczmy sieć \n",
    "(zwróćmy zwłaszcza uwagę na to co się dzieje w zagnieżdżonej pętli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2142
    },
    "colab_type": "code",
    "id": "ka2rxjOcnY_1",
    "outputId": "54b4f4fb-62dc-4079-e734-2752ba245c8b"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20 \n",
    "\n",
    "print('Training for {} epochs. \\n'.format(n_epochs))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    avg_cost = 0.0\n",
    "    avg_accuracy = 0.0\n",
    "    \n",
    "    for i, (X, y) in enumerate(train_loader): # enumerate() pozwala iterować po całym popaczkowanym zbiorze  \n",
    "    \n",
    "    # wykonujemy feed-forward:\n",
    "        X_flat = X.view(X.shape[0], -1)\n",
    "        y_hat = model(X_flat)\n",
    "        cost = cost_fxn(y_hat, y)\n",
    "        avg_cost += cost / n_batches\n",
    "    \n",
    "    # propagacja wsteczna i optymalizacja poprzez algorytm spadku gradientu: \n",
    "        optimizer.zero_grad() # ustawiamy gradienty w sieci na zero;\n",
    "        cost.backward() #obliczamy i zbieramy gradienty\n",
    "        optimizer.step() #aktualizujemy wagi z wykorzystaniem zebranych gradientów\n",
    "    \n",
    "    # obliczamy wartości wyznaczonej wcześniej metryki:\n",
    "        accuracy = accuracy_pct(y_hat, y)\n",
    "        avg_accuracy += accuracy / n_batches\n",
    "    \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Step {}'.format(i + 1))\n",
    "            \n",
    "        print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'.format(epoch + 1, n_epochs, avg_cost, avg_accuracy))\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmUI1Z7jj0XO"
   },
   "source": [
    "### Testujemy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4. Zaimplementuj w gotowej pętli obliczanie trafności na całym zbiorze testowym z wykorzystaniem funkcji accuracy_pct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DPU-rP_7jtk_",
    "outputId": "d9c513ed-4de9-4196-ea95-80487fcf5e78"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): # dezyaktywacja klasy autograd która oblicza pochodne i rejestruje graf wszystkich operacji wykonanych na tensorze, w tym przypadku chcemy zaoszczędzić pamięc\n",
    "    avg_test_cost = 0.0\n",
    "    avg_test_acc = 0.0\n",
    "    \n",
    "    for X, y in test_loader:\n",
    "    \n",
    "    # dokonujemy prognozy: \n",
    "        X_flat = X.view(X.shape[0], -1)\n",
    "        y_hat = model(X_flat)\n",
    "    \n",
    "    # obliczamy koszt: \n",
    "        cost = cost_fxn(y_hat, y)\n",
    "        avg_test_cost += cost / n_test_batches\n",
    "    \n",
    "    # tu odpowiedź - obliczamy trafność:\n",
    "        test_accuracy = \n",
    "        avg_test_acc += \n",
    "\n",
    "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5. Za pomocą dowolnej biblioteki wizualizacji przygotuj 2 wykresy/diagramy/histogramy ilustrujące zebrane wyniki wraz z opisem jakich informacji dostarczają przygotowane wykresy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "shallow_net_in_pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
